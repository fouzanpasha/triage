Voice model: Microsoft Azure Neural, ElevenLabs v3 (alpha), OpenAI “Voice Engine”

NLP/Reasoning (what u have above is okay for now)

Back-end: fine-tune some model (gpt-4o or llama)... this is where it takes transcription, prompts patient for questions, then when it has sufficient responses for pre-defined decsion pathways, it will either prompt patient that it will be transferred, suggest to see pharmacist first, or it may offer an appointment time.

Appointment booking (GP Connect?) find out the current software we saw in the video (EMIS Partner API???)

ETC...



Patient calls -- AI Answer

AI listens to the call from the patient, in this case the ai wil also be prompting questions just like a regular clerk

now is the logical portion/ deicsion making where the ai decides the next step, who to be contacted, appointment setting etc. This logic portion will be working with the patients data as well (EMIS or System 1 for patient data) 
                              -- Either we need an api that accesses this or the autonomeous agent will access it itself 

After the logical portion is decided, the conclusion will then be sent  to the doctor or physiciam etc and the patient as well via email or number

---------------
┌──────────────────────────┐
│        PSTN / SIP        │  Patient dials surgery’s main line
└────────────┬─────────────┘
             ▼  (RTP audio)
┌──────────────────────────┐
│  Telephony Edge (Twilio  │  • SIP trunk / WebRTC  
│  or local SBC)           │  • Streams PCMU → gRPC
└────────────┬─────────────┘
             ▼
┌──────────────────────────┐
│  ASR Service             │  • faster‑whisper on GPU  
│  (K8s pod, autoscaled)   │  • 15 s streaming chunks  
│                          │  → JSON {text, t0,t1,conf}
└────────────┬─────────────┘
             ▼
┌──────────────────────────┐
│  Dialogue Orchestrator   │  • Rasa 3 (graph + Llama 3)  
│  (“Reception‑Bot”)       │  • Function‑calling model  
│                          │  → intents + entities
└───────┬──────┬───────────┘
        │      │
        │      │─────────────────────────────────────────────────────────────┐
        │                                                                   │
        ▼                                                                   ▼
┌───────────────────────┐                                  ┌──────────────────────────┐
│  Triage Engine        │  A. Infermedica API *or*         │  Rules Firewall          │
│  (clinical logic)     │  B. NHS Pathways micro‑service   │  (regex red‑flags &      │
│                       │                                  │  safety thresholds)      │
└────────┬──────────────┘                                  └──────────┬───────────────┘
         ▼                                                                 ▼
   {urgency, reason}                                               escalate_999 | ok
         │                                                                 │
         └─────────────┬───────────────────────────────────────────────────┘
                       ▼
┌──────────────────────────┐
│  Scheduler Service       │  • Maps urgency ▸ slot policy                EMIS /      
│  (FHIR client)           │  • Queries & books via                       SystmOne    
│                          │    GP Connect Appointment API                FHIR APIs   
└────────────┬─────────────┘
             ▼
┌──────────────────────────┐
│  Notification Service    │  • Creates FHIR Task + HL7 FHIR Message to doctor inbox
│  (NHS Mail / Task API)   │  • Sends confirmation SMS via Gov.UK Notify
└────────────┬─────────────┘
             ▼
┌──────────────────────────┐
│  TTS Service             │  • Azure Neural TTS container (UK South)  
│  (streaming)             │  • SSML style=“empathetic”                 audio → caller
└──────────────────────────┘

-----------------------------


